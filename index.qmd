---
title: "Benchmark de GitHub Actions"
# Language
lang: fr-FR
otherlangs: en-GB
execute:
  # show code chunk output
  include: true
  # Show the code in the output
  echo: true
  # Show warnings
  warning: false
  # Cache code results
  cache: false
  # option messages is in the Option chunk for R
format: 
  html:
    toc: true
    filters: ["fr-nbsp.lua"]
editor: visual
---

```{r}
#| label: DoNotModify
#| include: false
### Utilities for R. 
# Do not modify unless you don't use R: then, delete this chunk.
# Installation of R packages if necessary
install_packages <- function(packages) {
  invisible(
    sapply(
      packages, 
      FUN = function(package) {
        if (!package %in% installed.packages()[, 1]) {
          install.packages(package, repos = "https://cran.rstudio.com/")
        }
      }
    )
  )
}

# Basic packages
install_packages(c("knitR", "formatR", "kableExtra"))

# Chunk font size hook: allows size='small' or any valid Latex font size in chunk options
def.chunk.hook <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(
  chunk = function(x, options) {
    x <- def.chunk.hook(x, options)
    ifelse(
      options$size == "normalsize", 
      yes = x,
      no = paste0("\n \\", options$size, "\n\n", x, "\n\n \\normalsize")
    )
  }
)
```

```{r}
#| label: Options
#| include: false
### Customized R options for this document
# Delete this chunk if you don't use R

# Add necessary packages here
packages <- c(
  "tidyverse", 
  "benchmarkme", 
  "spatstat", 
  "dbmss", 
  "microbenchmark",
  "profmem"
)
# Install them
install_packages(packages)

# knitr options (https://yihui.org/knitr/options/)
knitr::opts_chunk$set(
  # Messages from packages
  message = FALSE,
  # Code chunk automatic format if tidy is TRUE
  tidy = FALSE, 
  # Tidy code options: remove blank lines and cut lines after 50 characters
  tidy.opts = list(blank = FALSE, width.cutoff = 50),
  # Font size in PDF output
  size = "scriptsize", 
  # Select PDF figures in PDF output if PDF file exists beside PNG file
  knitr.graphics.auto_pdf = TRUE
)
# Text width of R functions output
options(width = 50)

# ggplot style
library("tidyverse")
theme_set(theme_bw())
theme_update(
  panel.background = element_rect(fill = "transparent", colour = NA),
  plot.background = element_rect(fill = "transparent", colour = NA)
)
knitr::opts_chunk$set(dev.args = list(bg = "transparent"))

# Random seed
set.seed(973)
```

## Hardware

```{r}
library("benchmarkme")
get_cpu()
get_ram()
get_platform_info()
```

## Performance

```{r}
res <- benchmark_std(runs = 3)
plot(res)
```

## Test d'un cas réel

```{r}
#| label: ParamsCSRCode
library("tidyverse")
library("spatstat")
library("dbmss")

par_points_nb <- 5000
par_case_ratio <- 1/20
par_size_gamma_shape <- 0.95
par_size_gamma_scale  <- 10
```

```{r}
#| label: XcsrCode
X_csr <- function(
    points_nb,
    case_ratio = par_case_ratio,
    size_gamma_shape = par_size_gamma_shape,
    size_gamma_scale = par_size_gamma_scale) {
  points_nb %>% 
    runifpoint() %>% 
    as.wmppp() ->
    X
  cases_nb <- round(points_nb *  case_ratio)
  controls_nb <- points_nb - cases_nb
  c(rep("Control", controls_nb), rep("Case", cases_nb)) %>% 
    as.factor() ->
    X$marks$PointType
  rgamma(
    X$n, 
    shape = size_gamma_shape, 
    scale = size_gamma_scale
  ) %>% 
    ceiling() ->
    X$marks$PointWeight
  X
}

# Example
X <- X_csr(par_points_nb)
# Map the cases
autoplot(X[X$marks$PointType == "Case"])
```

```{r}
#| label: ParamsrCode
r <- c((0:9) / 100, (2:10) / 20)
```

```{r}
#| label: XtoMCode
# Compute M
X_to_M <- function(X) {
  X %>% 
    Mhat(r = r, ReferenceType = "Case") %>% 
    pull("M")    
}
```

```{r}
#| label: ParamsXSizeCode
X_sizes <- c(1000, 5000, 10000, 50000, 100000)
```

```{r}
#| label: TestTimeCode
library("microbenchmark")
test_time <- function(points_nb) {
  X <- X_csr(points_nb)
  microbenchmark(X_to_M(X), times = 4L) %>% 
    pull("time")
}

X_sizes %>% 
  sapply(FUN = test_time) %>% 
  as_tibble() %>% 
  pivot_longer(cols = everything()) %>% 
  rename(Size = name) %>% 
  group_by(Size) %>% 
  summarise(Time = mean(value) / 1E9, sd = sd(value) / 1E9) %>% 
  mutate(
    Size = as.double(
      plyr::mapvalues(
        .$Size, 
        from = paste0("V", seq_along(X_sizes)), 
        to = X_sizes
      )
    )
  ) -> M_time
M_time %>% 
  ggplot(aes(x = Size, y = Time)) +
    geom_point() +
    geom_errorbar(aes(ymin = Time - sd, ymax = Time + sd)) +
    scale_x_log10() +
    scale_y_log10()
```

Temps d'exécution

```{r}
tibble(M_time)
```

```{r}
#| label: TimeModelCode
# Model
M_time %>% 
  mutate(logTime = log(Time), logSize = log(Size)) ->
  M_time_log
M_time_lm <- lm(logTime ~ logSize, data = M_time_log) 
summary(M_time_lm)
```

```{r}
#| label: TestMemCode
#| 
# RAM
library("profmem")
test_ram <- function(points_nb) {
  X <- X_csr(points_nb)
  profmem(X_to_M(X)) %>% 
    pull("bytes") %>% 
    sum(na.rm = TRUE)
}
sapply(X_sizes, FUN = test_ram) %>% 
  tibble(Size = X_sizes, RAM = . / 2^20) ->
  M_ram
M_ram %>% 
  ggplot(aes(x = Size, y = RAM)) +
    geom_point() +
    geom_line()
```

```{r}
#| label: MemModelCode
# Model
lm(RAM ~ Size, data = M_ram) %>% summary()
```

Temps d'exécution
```{r}
#| label: Mtime
# Time to compute 100000 points, in seconds
Mtime_1E5_s <- ceiling(M_time$Time[5])
# 1000 simulations, in minutes
Mtime_1E5_1000_min <- 1000  * Mtime_1E5_s / 60
# 5 million points, in minutes
Mtime_5E6_min <- exp(
  predict(
    M_time_lm, 
    newdata = data.frame(logSize = log(5E6))
  )
) / 60
# 1000 simulations, in days
Mtime_5E6_1000_d <- 1000 * Mtime_5E6_min / 60 / 24
```

::: {lang=en}
The calculation time for *M* is below `r format(Mtime_1E5_s, digits  = 1)` seconds for a set of 100,000 points on a modern comptuter[^10] and requires 25 MB of RAM.
Calculating a confidence interval from 1,000 simulations therefore takes less than `r format(Mtime_1E5_1000_min, digits  = 1)` minutes.
For a set of five million points, the power law predicts around `r round(Mtime_5E6_min)` minutes of computing time.
1,000 simulations would then take around `r round(Mtime_5E6_1000_d)` days.

[^10]: The results presented here were obtained on a GitHub-hosted runner under Mac OS with a virtual `r get_cpu()$no_of_cores`-core `r get_cpu()$model_name` CPU, similar to a fast laptop computer.
:::
